#!/usr/bin/env python3
"""
å®æ—¶åƒåœ¾è¯†åˆ«æ¨¡å—
ä½¿ç”¨OpenCVè¿›è¡Œæ‘„åƒå¤´æ•è·å’Œå®æ—¶é¢„æµ‹
"""

import cv2
import torch
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
import time
from collections import deque
import threading
import queue

# å¯¼å…¥æ¨¡å‹ç›¸å…³æ¨¡å—
from model_utils import get_device, load_model
from app import create_model, CLASS_MAPPING

class RealTimeTrashClassifier:
    def __init__(self, model_path=None, confidence_threshold=0.6):
        """
        åˆå§‹åŒ–å®æ—¶åƒåœ¾åˆ†ç±»å™¨
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        """
        self.device = get_device()
        self.confidence_threshold = confidence_threshold
        self.model = None
        self.class_names = None
        
        # é¢„æµ‹å†å²è®°å½•ï¼ˆç”¨äºç¨³å®šé¢„æµ‹ç»“æœï¼‰
        self.prediction_history = deque(maxlen=5)
        
        # æ‘„åƒå¤´è®¾ç½®
        self.cap = None
        self.is_running = False
        
        # é¢„æµ‹é˜Ÿåˆ—ï¼ˆç”¨äºå¼‚æ­¥é¢„æµ‹ï¼‰
        self.prediction_queue = queue.Queue(maxsize=1)
        self.current_prediction = None
        
        # åŠ è½½æ¨¡å‹
        self.load_model(model_path)
        
        # å›¾åƒé¢„å¤„ç†
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        print(f"âœ… å®æ—¶åƒåœ¾åˆ†ç±»å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   è®¾å¤‡: {self.device}")
        print(f"   ç½®ä¿¡åº¦é˜ˆå€¼: {confidence_threshold}")
    
    def load_model(self, model_path=None):
        """åŠ è½½æ¨¡å‹"""
        try:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šè·¯å¾„ï¼Œè‡ªåŠ¨å¯»æ‰¾æœ€æ–°æ¨¡å‹
            if model_path is None:
                import os
                if os.path.exists('models'):
                    model_files = [f for f in os.listdir('models') if f.endswith('.pth')]
                    if model_files:
                        # ä¼˜å…ˆé€‰æ‹©finalæ¨¡å‹
                        if 'trash_classifier_final.pth' in model_files:
                            model_path = os.path.join('models', 'trash_classifier_final.pth')
                        else:
                            # é€‰æ‹©æœ€æ–°çš„æ¨¡å‹
                            model_files.sort(key=lambda x: os.path.getmtime(os.path.join('models', x)), reverse=True)
                            model_path = os.path.join('models', model_files[0])
                    else:
                        raise FileNotFoundError("æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
                else:
                    raise FileNotFoundError("modelsç›®å½•ä¸å­˜åœ¨")
            
            # åˆ›å»ºå¹¶åŠ è½½æ¨¡å‹ï¼ˆä½¿ç”¨æ­£ç¡®çš„ResNet50æ¶æ„ï¼‰
            import torchvision.models as models
            import torch.nn as nn
            
            self.model = models.resnet50(weights=None)
            self.model.fc = nn.Sequential(
                nn.Dropout(0.5),
                nn.Linear(self.model.fc.in_features, 6)  # 6ä¸ªç±»åˆ«
            )
            
            self.model, self.class_names = load_model(self.model, model_path)
            self.model.eval()
            
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
            print(f"   æ”¯æŒç±»åˆ«: {self.class_names}")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise e
    
    def preprocess_frame(self, frame):
        """é¢„å¤„ç†æ‘„åƒå¤´å¸§"""
        # è½¬æ¢BGRåˆ°RGB
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # è½¬æ¢ä¸ºPILå›¾åƒ
        pil_image = Image.fromarray(rgb_frame)
        
        # åº”ç”¨å˜æ¢
        tensor = self.transform(pil_image).unsqueeze(0).to(self.device)
        
        return tensor, pil_image
    
    def predict_frame(self, frame):
        """é¢„æµ‹å•å¸§å›¾åƒ"""
        try:
            if self.model is None:
                return None
            
            # é¢„å¤„ç†
            tensor, pil_image = self.preprocess_frame(frame)
            
            # é¢„æµ‹
            with torch.no_grad():
                outputs = self.model(tensor)
                probabilities = torch.nn.functional.softmax(outputs, dim=1)[0]
                predicted_idx = torch.argmax(probabilities).item()
                confidence = probabilities[predicted_idx].item()
            
            # è·å–é¢„æµ‹ç»“æœ
            predicted_class = self.class_names[predicted_idx]
            
            # è·å–æ‰€æœ‰ç±»åˆ«çš„ç½®ä¿¡åº¦
            all_confidences = {
                self.class_names[i]: probabilities[i].item() 
                for i in range(len(self.class_names))
            }
            
            return {
                'class': predicted_class,
                'confidence': confidence,
                'all_confidences': all_confidences,
                'timestamp': time.time()
            }
            
        except Exception as e:
            print(f"é¢„æµ‹é”™è¯¯: {e}")
            return None
    
    def get_stable_prediction(self, new_prediction):
        """è·å–ç¨³å®šçš„é¢„æµ‹ç»“æœï¼ˆåŸºäºå†å²è®°å½•ï¼‰"""
        if new_prediction is None:
            return self.current_prediction
        
        # æ·»åŠ åˆ°å†å²è®°å½•
        self.prediction_history.append(new_prediction)
        
        # å¦‚æœç½®ä¿¡åº¦è¶³å¤Ÿé«˜ï¼Œç›´æ¥è¿”å›
        if new_prediction['confidence'] > 0.8:
            return new_prediction
        
        # å¦åˆ™åŸºäºå†å²è®°å½•è¿›è¡Œå¹³æ»‘
        if len(self.prediction_history) >= 3:
            # ç»Ÿè®¡æœ€å¸¸è§çš„ç±»åˆ«
            class_counts = {}
            total_confidence = 0
            
            for pred in self.prediction_history:
                cls = pred['class']
                conf = pred['confidence']
                
                if cls not in class_counts:
                    class_counts[cls] = {'count': 0, 'total_conf': 0}
                
                class_counts[cls]['count'] += 1
                class_counts[cls]['total_conf'] += conf
                total_confidence += conf
            
            # æ‰¾åˆ°æœ€å¸¸è§ä¸”ç½®ä¿¡åº¦åˆç†çš„ç±»åˆ«
            best_class = max(class_counts.items(), 
                           key=lambda x: x[1]['count'] * x[1]['total_conf'])
            
            avg_confidence = best_class[1]['total_conf'] / best_class[1]['count']
            
            if avg_confidence > self.confidence_threshold:
                return {
                    'class': best_class[0],
                    'confidence': avg_confidence,
                    'all_confidences': new_prediction['all_confidences'],
                    'timestamp': new_prediction['timestamp'],
                    'stable': True
                }
        
        return new_prediction
    
    def async_predict(self, frame):
        """å¼‚æ­¥é¢„æµ‹ï¼ˆåœ¨å•ç‹¬çº¿ç¨‹ä¸­ï¼‰"""
        if not self.prediction_queue.full():
            try:
                self.prediction_queue.put_nowait(frame)
            except queue.Full:
                pass
    
    def prediction_worker(self):
        """é¢„æµ‹å·¥ä½œçº¿ç¨‹"""
        while self.is_running:
            try:
                frame = self.prediction_queue.get(timeout=0.1)
                prediction = self.predict_frame(frame)
                self.current_prediction = self.get_stable_prediction(prediction)
                self.prediction_queue.task_done()
            except queue.Empty:
                continue
            except Exception as e:
                print(f"é¢„æµ‹çº¿ç¨‹é”™è¯¯: {e}")
    
    def start_camera(self, camera_id=0):
        """å¯åŠ¨æ‘„åƒå¤´"""
        try:
            self.cap = cv2.VideoCapture(camera_id)
            
            if not self.cap.isOpened():
                raise RuntimeError(f"æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {camera_id}")
            
            # è®¾ç½®æ‘„åƒå¤´å‚æ•°
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.cap.set(cv2.CAP_PROP_FPS, 30)
            
            self.is_running = True
            
            # å¯åŠ¨é¢„æµ‹çº¿ç¨‹
            self.prediction_thread = threading.Thread(target=self.prediction_worker, daemon=True)
            self.prediction_thread.start()
            
            print("âœ… æ‘„åƒå¤´å¯åŠ¨æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ æ‘„åƒå¤´å¯åŠ¨å¤±è´¥: {e}")
            return False
    
    def stop_camera(self):
        """åœæ­¢æ‘„åƒå¤´"""
        self.is_running = False
        
        if self.cap is not None:
            self.cap.release()
            
        cv2.destroyAllWindows()
        print("âœ… æ‘„åƒå¤´å·²åœæ­¢")
    
    def draw_prediction_overlay(self, frame, prediction):
        """åœ¨å¸§ä¸Šç»˜åˆ¶é¢„æµ‹ç»“æœè¦†ç›–å±‚"""
        if prediction is None:
            # æ˜¾ç¤º"æ­£åœ¨è¯†åˆ«..."
            cv2.putText(frame, "Detecting...", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
            return frame
        
        # è·å–ç±»åˆ«ä¿¡æ¯
        eng_class = prediction['class']
        confidence = prediction['confidence']
        
        class_info = CLASS_MAPPING.get(eng_class, {
            'chinese': eng_class,
            'icon': 'â“',
            'color': '#808080'
        })
        
        # ç¡®å®šé¢œè‰²ï¼ˆåŸºäºç½®ä¿¡åº¦ï¼‰
        if confidence > 0.8:
            color = (0, 255, 0)  # ç»¿è‰² - é«˜ç½®ä¿¡åº¦
        elif confidence > 0.6:
            color = (0, 255, 255)  # é»„è‰² - ä¸­ç­‰ç½®ä¿¡åº¦
        else:
            color = (0, 0, 255)  # çº¢è‰² - ä½ç½®ä¿¡åº¦
        
        # ç»˜åˆ¶ä¸»è¦ç»“æœ
        chinese_name = class_info['chinese']
        main_text = f"{class_info['icon']} {chinese_name}"
        confidence_text = f"Confidence: {confidence:.1%}"
        
        # ç»˜åˆ¶åŠé€æ˜èƒŒæ™¯
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, 10), (400, 120), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        # ç»˜åˆ¶æ–‡æœ¬
        cv2.putText(frame, main_text, (20, 40), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
        cv2.putText(frame, confidence_text, (20, 70), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        cv2.putText(frame, f"English: {eng_class}", (20, 95), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # ç»˜åˆ¶ç½®ä¿¡åº¦æ¡
        bar_width = int(300 * confidence)
        cv2.rectangle(frame, (20, 105), (320, 115), (100, 100, 100), 1)
        cv2.rectangle(frame, (20, 105), (20 + bar_width, 115), color, -1)
        
        # ç»˜åˆ¶å…¶ä»–ç±»åˆ«çš„ç½®ä¿¡åº¦ï¼ˆå‰3ä¸ªï¼‰
        y_offset = 140
        sorted_confidences = sorted(prediction['all_confidences'].items(), 
                                  key=lambda x: x[1], reverse=True)
        
        for i, (cls, conf) in enumerate(sorted_confidences[:3]):
            if cls != eng_class:  # è·³è¿‡ä¸»è¦é¢„æµ‹ç±»åˆ«
                cls_info_other = CLASS_MAPPING.get(cls, {'chinese': cls, 'icon': 'â“'})
                other_text = f"{cls_info_other['icon']} {cls_info_other['chinese']}: {conf:.1%}"
                cv2.putText(frame, other_text, (20, y_offset), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)
                y_offset += 20
        
        return frame
    
    def run_realtime(self):
        """è¿è¡Œå®æ—¶è¯†åˆ«"""
        if not self.start_camera():
            return
        
        print("ğŸ¥ å®æ—¶åƒåœ¾è¯†åˆ«å·²å¯åŠ¨")
        print("   æŒ‰ 'q' é”®é€€å‡º")
        print("   æŒ‰ 's' é”®æˆªå›¾ä¿å­˜")
        
        frame_count = 0
        last_prediction_time = 0
        
        try:
            while self.is_running:
                ret, frame = self.cap.read()
                if not ret:
                    print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
                    break
                
                frame_count += 1
                current_time = time.time()
                
                # æ¯éš”å‡ å¸§è¿›è¡Œä¸€æ¬¡é¢„æµ‹ï¼ˆå‡å°‘è®¡ç®—è´Ÿæ‹…ï¼‰
                if frame_count % 5 == 0 and current_time - last_prediction_time > 0.5:
                    self.async_predict(frame.copy())
                    last_prediction_time = current_time
                
                # ç»˜åˆ¶é¢„æµ‹ç»“æœ
                frame_with_overlay = self.draw_prediction_overlay(frame, self.current_prediction)
                
                # æ·»åŠ FPSä¿¡æ¯
                fps_text = f"FPS: {1.0 / (current_time - last_prediction_time + 0.001):.1f}"
                cv2.putText(frame_with_overlay, fps_text, (500, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                # æ˜¾ç¤ºç”»é¢
                cv2.imshow('Real-time Trash Classification', frame_with_overlay)
                
                # æ£€æŸ¥æŒ‰é”®
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('s'):
                    # ä¿å­˜æˆªå›¾
                    timestamp = int(time.time())
                    filename = f"screenshot_{timestamp}.jpg"
                    cv2.imwrite(filename, frame_with_overlay)
                    print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {filename}")
        
        except KeyboardInterrupt:
            print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
        
        except Exception as e:
            print(f"âŒ è¿è¡Œæ—¶é”™è¯¯: {e}")
        
        finally:
            self.stop_camera()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨å®æ—¶åƒåœ¾åˆ†ç±»è¯†åˆ«ç³»ç»Ÿ...")
    
    try:
        # åˆ›å»ºåˆ†ç±»å™¨
        classifier = RealTimeTrashClassifier(confidence_threshold=0.5)
        
        # è¿è¡Œå®æ—¶è¯†åˆ«
        classifier.run_realtime()
        
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
