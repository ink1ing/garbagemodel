# ğŸ¤– åƒåœ¾åˆ†ç±»AIè¯†åˆ«ç³»ç»Ÿ - é¡¹ç›®æ€»ç»“

## ğŸ“‹ é¡¹ç›®æ ¸å¿ƒ

åŸºäº **ResNet50 + PyTorch** çš„æ™ºèƒ½åƒåœ¾åˆ†ç±»ç³»ç»Ÿï¼Œæ”¯æŒ **å®æ—¶æ‘„åƒå¤´è¯†åˆ«** + **Webç•Œé¢** + **äºŒç»´ç ç®¡ç†**ï¼Œè¯†åˆ«å‡†ç¡®ç‡è¾¾åˆ° **96.4%**ã€‚

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

- **6ç±»åƒåœ¾è¯†åˆ«**: çº¸æ¿ã€ç»ç’ƒã€é‡‘å±ã€çº¸å¼ ã€å¡‘æ–™ã€å…¶ä»–åƒåœ¾
- **å®æ—¶è§†é¢‘æµ**: 1080p@60fps é«˜æ¸…è¯†åˆ«  
- **Webç•Œé¢**: GitHubé£æ ¼æ·±è‰²ä¸»é¢˜
- **äºŒç»´ç ç®¡ç†**: åƒåœ¾æ¡¶ç»‘å®šä¸è¿½è¸ª
- **Apple Siliconä¼˜åŒ–**: MPS GPUåŠ é€Ÿ

## ğŸ“ é¡¹ç›®ç»“æ„

```
canva1/
â”œâ”€â”€ ğŸ”¥ æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ app.py                    # æ¨¡å‹å®šä¹‰ + ç±»åˆ«æ˜ å°„
â”‚   â”œâ”€â”€ train.py                  # æ¨¡å‹è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ realtime_classifier.py    # å®æ—¶åˆ†ç±»å™¨
â”‚   â””â”€â”€ web_realtime.py          # Flask WebæœåŠ¡
â”‚
â”œâ”€â”€ ğŸŒ Webç•Œé¢
â”‚   â””â”€â”€ templates/
â”‚       â”œâ”€â”€ realtime_index.html  # ä¸»ç•Œé¢ (GitHubæ·±è‰²ä¸»é¢˜)
â”‚       â””â”€â”€ simple_test.html     # ç®€åŒ–æµ‹è¯•é¡µé¢
â”‚
â”œâ”€â”€ ğŸ·ï¸ äºŒç»´ç ç³»ç»Ÿ
â”‚   â”œâ”€â”€ qr_manager.py            # äºŒç»´ç ç®¡ç†å™¨
â”‚   â”œâ”€â”€ qr_tool.py               # å‘½ä»¤è¡Œå·¥å…·
â”‚   â””â”€â”€ QR_README.md             # äºŒç»´ç æ–‡æ¡£
â”‚
â”œâ”€â”€ ğŸ“Š åˆ†æå·¥å…·
â”‚   â”œâ”€â”€ generate_confusion_matrix.py    # æ··æ·†çŸ©é˜µç”Ÿæˆ
â”‚   â”œâ”€â”€ generate_training_charts.py     # è®­ç»ƒå›¾è¡¨ç”Ÿæˆ
â”‚   â””â”€â”€ model_utils.py                  # æ¨¡å‹å·¥å…·å‡½æ•°
â”‚
â”œâ”€â”€ ğŸ“ˆ ç»“æœæ–‡ä»¶
â”‚   â”œâ”€â”€ models/                   # è®­ç»ƒå¥½çš„æ¨¡å‹
â”‚   â”œâ”€â”€ results/charts/           # åˆ†æå›¾è¡¨
â”‚   â””â”€â”€ qr_codes/                # äºŒç»´ç å­˜å‚¨
â”‚
â””â”€â”€ ğŸ“– æ–‡æ¡£
    â”œâ”€â”€ README.md                # ä¸»æ–‡æ¡£
    â”œâ”€â”€ advtg.md                 # æŠ€æœ¯ä¼˜åŠ¿åˆ†æ
    â””â”€â”€ final.md                 # é¡¹ç›®æ€»ç»“ (æœ¬æ–‡ä»¶)
```

## ğŸ”§ æ ¸å¿ƒä»£ç æ¶æ„

### 1. æ¨¡å‹å®šä¹‰ (`app.py`)
```python
def create_model(num_classes):
    # ResNet50 + è¿ç§»å­¦ä¹ 
    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
    
    # å†»ç»“å‰20å±‚ï¼Œå¾®è°ƒå30å±‚
    for param in list(model.parameters())[:-30]:
        param.requires_grad = False
    
    # è‡ªå®šä¹‰åˆ†ç±»å¤´
    model.fc = nn.Sequential(
        nn.Dropout(0.5),
        nn.Linear(model.fc.in_features, num_classes)
    )
    return model

# 6ç±»åƒåœ¾æ˜ å°„
CLASS_MAPPING = {
    'cardboard': {'chinese': 'çº¸æ¿', 'icon': 'ğŸ“¦'},
    'glass': {'chinese': 'ç»ç’ƒ', 'icon': 'ğŸ¶'},
    'metal': {'chinese': 'é‡‘å±', 'icon': 'ğŸ”§'},
    'paper': {'chinese': 'çº¸å¼ ', 'icon': 'ğŸ“„'},
    'plastic': {'chinese': 'å¡‘æ–™', 'icon': 'ğŸ¥¤'},
    'trash': {'chinese': 'å…¶ä»–åƒåœ¾', 'icon': 'ğŸ—‘ï¸'}
}
```

### 2. å®æ—¶åˆ†ç±»å™¨ (`realtime_classifier.py`)
```python
class RealTimeTrashClassifier:
    def __init__(self, confidence_threshold=0.7):
        self.device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
        self.model = self._load_model()
        self.prediction_history = deque(maxlen=5)  # å¹³æ»‘é¢„æµ‹
        
    def start_camera(self, camera_id=0):
        # å¤šåç«¯æ”¯æŒ: AVFoundation â†’ CAP_ANY
        backends = [cv2.CAP_AVFOUNDATION, cv2.CAP_ANY]
        for backend in backends:
            self.cap = cv2.VideoCapture(camera_id, backend)
            if self.cap.isOpened():
                # 1080p@60fps é«˜è´¨é‡è®¾ç½®
                self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
                self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
                self.cap.set(cv2.CAP_PROP_FPS, 60)
                return True
        return False
    
    def predict_frame(self, frame):
        # å›¾åƒé¢„å¤„ç† â†’ æ¨¡å‹æ¨ç† â†’ åå¤„ç†
        processed_frame = self.transform(Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))
        
        with torch.no_grad():
            outputs = self.model(processed_frame.unsqueeze(0).to(self.device))
            probabilities = F.softmax(outputs, dim=1)
            
        return self._format_prediction(probabilities)
```

### 3. WebæœåŠ¡å™¨ (`web_realtime.py`)
```python
@app.route('/video_feed')
def video_feed():
    return Response(generate_frames(), 
                   mimetype='multipart/x-mixed-replace; boundary=frame')

def generate_frames():
    # 30fps è§†é¢‘æµ + å®æ—¶é¢„æµ‹è¦†ç›–
    while is_streaming:
        ret, frame = classifier.cap.read()
        
        # æ¯15å¸§é¢„æµ‹ä¸€æ¬¡ (æ€§èƒ½ä¼˜åŒ–)
        if frame_count % 15 == 0:
            classifier.async_predict(frame.copy())
        
        # ç»˜åˆ¶é¢„æµ‹è¦†ç›–å±‚
        frame_with_overlay = classifier.draw_prediction_overlay(frame)
        
        # JPEGç¼–ç  + æµå¼ä¼ è¾“
        ret, buffer = cv2.imencode('.jpg', frame_with_overlay, 
                                  [cv2.IMWRITE_JPEG_QUALITY, 80])
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')
```

### 4. äºŒç»´ç ç®¡ç† (`qr_manager.py`)
```python
class QRCodeManager:
    def __init__(self, storage_dir="qr_codes"):
        self.active_dir = os.path.join(storage_dir, "active")      # æ´»è·ƒäºŒç»´ç 
        self.archived_dir = os.path.join(storage_dir, "archived")  # å·²ä½œåºŸ
        self.captured_dir = os.path.join(storage_dir, "captured")  # å·²è·å–
        
    def generate_qr_codes(self, count):
        # æ‰¹é‡ç”Ÿæˆ no.1 ~ no.{count} çš„äºŒç»´ç 
        for i in range(1, count + 1):
            bin_id = f"no.{i}"
            qr_data = {
                "bin_id": bin_id,
                "unique_id": str(uuid.uuid4()),
                "created_time": datetime.now().isoformat(),
                "type": "trash_bin_qr",
                "status": "active"
            }
            self._generate_qr_image(qr_data, bin_id)
```

## ğŸš€ æ ¸å¿ƒå‘½ä»¤

```bash
# ç¯å¢ƒæ¿€æ´»
source trash_classifier_env/bin/activate

# æ¨¡å‹è®­ç»ƒ (15è½®ï¼Œ96.4%å‡†ç¡®ç‡)
python train.py --epochs 15

# å¯åŠ¨WebæœåŠ¡ (è®¿é—® http://localhost:5001)
python web_realtime.py

# ç”Ÿæˆè¯„ä¼°å›¾è¡¨
python generate_confusion_matrix.py
python generate_training_charts.py

# äºŒç»´ç ç®¡ç†
python qr_tool.py -g 5        # ç”Ÿæˆ5ä¸ªäºŒç»´ç 
python qr_tool.py --get no.5  # è·å–no.5äºŒç»´ç 
python qr_tool.py --list      # æŸ¥çœ‹æ‰€æœ‰äºŒç»´ç 
```

## ğŸ“Š æŠ€æœ¯æŒ‡æ ‡

| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |
|------|------|------|
| **è¯†åˆ«å‡†ç¡®ç‡** | 96.4% | åŸºäºResNet50è¿ç§»å­¦ä¹  |
| **æ¨ç†å»¶è¿Ÿ** | <50ms | Apple Silicon MPSåŠ é€Ÿ |
| **è§†é¢‘å¸§ç‡** | 60fps@1080p | é«˜æ¸…å®æ—¶è¯†åˆ« |
| **æ¨¡å‹å¤§å°** | ~100MB | é€‚åˆè¾¹ç¼˜éƒ¨ç½² |
| **æ”¯æŒç±»åˆ«** | 6ç±» | cardboard/glass/metal/paper/plastic/trash |

## ğŸ¨ ç•Œé¢ç‰¹è‰²

- **GitHubæ·±è‰²ä¸»é¢˜**: ä¸“ä¸šçº§UIè®¾è®¡
- **å“åº”å¼å¸ƒå±€**: æ”¯æŒæ¡Œé¢+ç§»åŠ¨ç«¯
- **å®æ—¶é¢„æµ‹æ˜¾ç¤º**: ç½®ä¿¡åº¦æ¡å½¢å›¾ + ä¸­æ–‡æ ‡ç­¾
- **æ™ºèƒ½çŠ¶æ€æŒ‡ç¤º**: æ‘„åƒå¤´çŠ¶æ€ + å¸§ç‡ç›‘æ§

## ğŸ”— ç³»ç»Ÿé›†æˆ

```python
# ä¸äºŒç»´ç ç³»ç»Ÿé›†æˆç¤ºä¾‹
@app.route('/scan_qr')
def scan_qr():
    qr_data = request.json.get('qr_data')
    bin_info = json.loads(qr_data)
    
    # è®°å½•æŠ•æ”¾è¡Œä¸º
    log_disposal_event(bin_info['bin_id'], current_prediction)
    
    return jsonify({
        'bin_id': bin_info['bin_id'],
        'suggestion': get_disposal_suggestion(bin_info['bin_id'])
    })

# å®æ—¶è¯†åˆ«ä¸­çš„äºŒç»´ç æ£€æµ‹
def detect_qr_in_frame(frame):
    # OpenCV + pyzbar æ£€æµ‹äºŒç»´ç 
    # è¿”å›åƒåœ¾æ¡¶ä¿¡æ¯ç”¨äºæ™ºèƒ½æé†’
    pass
```

## ğŸ† é¡¹ç›®äº®ç‚¹

1. **æ·±åº¦å­¦ä¹ **: ResNet50 + è¿ç§»å­¦ä¹ ï¼Œ96.4%é«˜ç²¾åº¦è¯†åˆ«
2. **å®æ—¶æ€§èƒ½**: Apple Siliconä¼˜åŒ–ï¼Œ<50msæ¨ç†å»¶è¿Ÿ
3. **å®Œæ•´Webç•Œé¢**: Flask + GitHubé£æ ¼æ·±è‰²ä¸»é¢˜  
4. **äºŒç»´ç ç®¡ç†**: æ”¯æŒåƒåœ¾æ¡¶ç»‘å®šã€çŠ¶æ€è¿½è¸ªã€æ‰¹é‡æ“ä½œ
5. **å¯è§†åŒ–åˆ†æ**: æ··æ·†çŸ©é˜µã€è®­ç»ƒæ›²çº¿ã€æ€§èƒ½æŒ‡æ ‡
6. **ç”Ÿäº§å°±ç»ª**: æ¨¡å—åŒ–æ¶æ„ã€é”™è¯¯å¤„ç†ã€æ—¥å¿—ç³»ç»Ÿ

## ğŸ”® åº”ç”¨åœºæ™¯

- **æ™ºèƒ½åƒåœ¾æ¡¶**: å®æ—¶è¯†åˆ« + æŠ•æ”¾å»ºè®®
- **ç¯ä¿æ•™è‚²**: äº’åŠ¨å­¦ä¹  + æ¸¸æˆåŒ–ä½“éªŒ  
- **å·¥ä¸šåˆ†æ‹£**: é«˜ç²¾åº¦è‡ªåŠ¨åŒ–åˆ†ç±»
- **æ•°æ®ç»Ÿè®¡**: æŠ•æ”¾è¡Œä¸ºåˆ†æ + ä¼˜åŒ–å»ºè®®

---

**ğŸ¯ æ€»ç»“**: è¿™æ˜¯ä¸€ä¸ªé›†AIè¯†åˆ«ã€Webç•Œé¢ã€äºŒç»´ç ç®¡ç†äºä¸€ä½“çš„å®Œæ•´åƒåœ¾åˆ†ç±»è§£å†³æ–¹æ¡ˆï¼ŒæŠ€æœ¯æ ˆå…ˆè¿›ã€æ€§èƒ½ä¼˜å¼‚ã€åŠŸèƒ½å®Œå¤‡ï¼Œå¯ç›´æ¥ç”¨äºç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ã€‚
